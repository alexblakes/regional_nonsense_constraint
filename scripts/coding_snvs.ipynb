{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.5", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "toc-autonumbering": false, "toc-showcode": false}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "code", "source": "\"\"\" This script finds every possible SNV within the regions of interest.\nIt also annotates the trinucleotide context around each SNV.\n\nIt takes the output of a bedtools getfasta command (tsv) as input.\n\nNB the coordinates of each feature should be extended by 1 each side with\nbedtools slop, so that the 3nt context around the most 5' and 3' positions\nis still accessible.\n\"\"\";", "metadata": {}, "execution_count": 1, "outputs": []}, {"cell_type": "code", "source": "# Import relevant modules\nimport numpy as np\nimport pandas as pd", "metadata": {}, "execution_count": 2, "outputs": []}, {"cell_type": "code", "source": "def get_tri_contexts(getfasta_output):\n    \"\"\"Get trinucleotide context for each nt within a genomic feature.\n\n    Takes the .tsv output from a bedtools getfasta command.\n\n    NB the coordinates of each feature should be extended by 1 each side with\n    bedtools slop, so that the 3nt context around the most 5' and 3' positions\n    is still accessible.\n    \"\"\"\n\n    print(f\"Getting trinucleotide contexts for {getfasta_output}\")\n\n    # Read data\n    df = pd.read_csv(\n        getfasta_output,\n        sep=\"\\t\",\n        header=None,\n        names=[\"id\", \"seq\"],\n    )\n    print(f\"There are {len(df)} features\")\n\n    # Extract chr, start, and end information\n    a = df[\"id\"].str.split(\":\")\n    b = a.str[1].str.split(\"-\")\n    df[\"chr\"] = a.str[0]\n    df[\"start\"] = b.str[0].astype(int) + 1  # revert to 1-based\n    df[\"end\"] = b.str[1].astype(int)\n\n    # Get the position and ref allele for every nt within the feature.\n    pos = lambda x: range(x[\"start\"], x[\"end\"] + 1)\n    df[\"pos\"] = df.apply(pos, axis=1)\n\n    ref = lambda x: list(zip(x[\"pos\"], x[\"seq\"]))\n    df[\"ref\"] = df.apply(ref, axis=1)\n\n    df = df[[\"chr\", \"ref\"]].explode(\"ref\")\n\n    df[\"pos\"] = [x[0] for x in df[\"ref\"]]\n    df[\"ref\"] = [x[1] for x in df[\"ref\"]]\n\n    print(f\"They span {len(df)} nt before trimming of the most 3' and 5' positions\")\n\n    # Get trinucleotide context around each position.\n    df = df.reset_index(names=\"cds\")  # Unique ID for each feature\n    df = df.sort_values([\"cds\", \"pos\"])  # Ensure order of positions\n\n    first = df.groupby([\"cds\"])[\"ref\"].shift(1)  # Order preserved by groupby\n    last = df.groupby([\"cds\"])[\"ref\"].shift(-1)\n    tri = first.str.cat(others=[df[\"ref\"], last]).rename(\"tri\")  # Get triplet context\n\n    df = pd.concat([df, tri], axis=1)  # Extreme ends contain NaNs: useful for dropping\n    print(\n        f\"There are {df.tri.isna().sum()} positions at the extreme ends of the features.\"\n    )\n    df = df.dropna()  # Drop extreme end positions\n    df = df.sort_values([\"chr\", \"pos\"])  # Sort for faster VEP annotation\n    print(f\"There are {len(df)} nt after trimming.\")\n\n    # Get possible alt alleles for each position.\n    df[\"alt\"] = [[\"A\", \"T\", \"C\", \"G\"]] * len(df)\n    df = df.explode(\"alt\")\n    df = df[df[\"ref\"] != df[\"alt\"]]\n    df = df[[\"chr\", \"pos\", \"ref\", \"alt\", \"tri\"]].reset_index(drop=True)\n    print(f\"There are {df.duplicated().sum()} identical duplicate positions\")\n\n    # Tidy the dataframe\n    df = df.drop_duplicates()\n    df = df[df[\"ref\"] != \"N\"]  # Mainly chrY positions\n    print(f\"There are {len(df)} possible SNVs\")\n\n    return df", "metadata": {}, "execution_count": 3, "outputs": []}, {"cell_type": "code", "source": "if __name__ == \"__main__\":\n\n    get_fasta_output = \"../outputs/gencode_v39_canonical_cds_seq.tsv\"\n\n    # Combine NMD-pos and NMD-esc regions\n    df = get_tri_contexts(get_fasta_output)\n    print(f\"There are {len(df)} distinct possible SNVs in all CDS features.\")\n    print(\"Writing trinucleotide contexts to .tsv\")\n    df.to_csv(\"../outputs/cds_trinucleotide_contexts.tsv\", sep=\"\\t\", index=False)\n\n    # Create a VCF file for VEP annotation\n    vcf = df.copy().assign(ID=\".\", QUAL=\".\", FILTER=\".\", INFO=\".\")\n    vcf = vcf[[\"chr\", \"pos\", \"ID\", \"ref\", \"alt\", \"QUAL\", \"FILTER\", \"INFO\"]]\n    print(\"Writing SNVs to .vcf\")\n    vcf.to_csv(\n        \"../outputs/cds_all_possible_snvs.vcf\", sep=\"\\t\", index=False, header=False\n    )", "metadata": {}, "execution_count": 4, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Getting trinucleotide contexts for ../outputs/gencode_v39_canonical_cds_seq.tsv\n\nThere are 196885 features\n\nThey span 34571741 nt before trimming of the most 3' and 5' positions\n\nThere are 393770 positions at the extreme ends of the features.\n\nThere are 34177971 nt after trimming.\n\nThere are 1813980 identical duplicate positions\n\nThere are 100651272 possible SNVs\n\nThere are 100651272 distinct possible SNVs in all CDS features.\n\nWriting .tsv\n\nWriting .vcf\n"}]}]}
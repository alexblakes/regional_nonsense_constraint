{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.5", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "This script determines the number of expected and observed variants per transcript. ", "metadata": {}}, {"cell_type": "markdown", "source": "# Libraries", "metadata": {}}, {"cell_type": "code", "source": "import numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom statsmodels.stats.proportion import proportions_ztest\n\nsns.set_context(\"talk\")", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Define VCF headers and datatypes.\nheader = [\"chr\", \"pos\", \"id\", \"ref\", \"alt\", \"qual\", \"filter\", \"info\"]\n\ndatatypes = defaultdict(lambda: \"str\")\ndatatypes.update({\"pos\": np.int32, \"ac\": np.int32, \"an\": np.int32})", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "# Datasets", "metadata": {}}, {"cell_type": "code", "source": "# Retreive VEP annotations of all possible SNVs\nvep = pd.read_csv(\n    \"../outputs/vep/vep_cds_all_possible_snvs.vcf\",\n    sep=\"\\t\",\n    comment=\"#\",\n    header=None,\n    names=header,\n    dtype=datatypes,\n    usecols=[\"chr\", \"pos\", \"ref\", \"alt\", \"info\"],\n)", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Get enst\nvep[\"enst\"] = pd.Series([x.split(\"|\", 3)[2] for x in vep[\"info\"]])", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Get csq\nsyn = pd.Series([\"synonymous\" in x for x in vep[\"info\"]])\nmis = pd.Series([\"missense\" in x for x in vep[\"info\"]])\nnon = pd.Series([\"stop_gained\" in x for x in vep[\"info\"]])\n\nvep.loc[syn, \"csq\"] = \"synonymous\"\nvep.loc[mis, \"csq\"] = \"missense\"\nvep.loc[non, \"csq\"] = \"nonsense\"\n\nvep = vep.drop(\"info\", axis=1).dropna()  # Keep only syn/mis/non variants", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Observed variants\nobs = (\n    pd.read_csv(\n        \"/re_gecip/enhanced_interpretation/AlexBlakes/gene_terminus_variant_constraint/outputs/gnomad/snvs_gnomad_cds.vcf\",\n        sep=\"\\t\",\n        header=None,\n        names=header + [\"ac\", \"an\"],\n        usecols=[\"chr\", \"pos\", \"ref\", \"alt\"],\n        dtype=datatypes,\n    )\n    .drop_duplicates()\n    .assign(obs=1)\n)", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Trinucleotide contexts\ntri = pd.read_csv(\n    \"../outputs/cds_trinucleotide_contexts.tsv\", sep=\"\\t\", dtype=datatypes\n)", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Coverage data\ncov = pd.read_csv(\n    \"../outputs/gnomad_3.1.1_coverage_coding_sites.tsv\",\n    sep=\"\\t\",\n    usecols=[\"chr\", \"pos\", \"median_cov\"],\n)\ncov.loc[cov[\"median_cov\"] > 35, \"median_cov\"] = 35", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# ENCODE methylation data\nmeth = pd.read_csv(\"../outputs/encode_testis_methylation.tsv\", sep=\"\\t\")\n\n# Cut methylation scores into bins (as per gnomAD)\nbins = [\n    0,\n    0.05,\n    0.1,\n    0.15,\n    0.2,\n    0.25,\n    0.3,\n    0.5,\n    0.55,\n    0.6,\n    0.65,\n    0.7,\n    0.75,\n    0.8,\n    0.85,\n    0.9,\n    1,\n]\nmeth[\"lvl\"] = pd.cut(\n    (meth.methylation / 100), bins=bins, labels=list(range(16)), include_lowest=True\n).astype(\"int\")\nmeth = meth.drop(\"methylation\", axis=1)", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Mutation rates\nmu = pd.read_csv(\n    \"../data/gnomad_nc_mutation_rates.tsv\",\n    sep=\"\\t\",\n    names=([\"tri\", \"ref\", \"alt\", \"lvl\", \"variant_type\", \"mu\"] + list(range(4))),\n    header=0,\n    usecols=[\"tri\", \"ref\", \"alt\", \"lvl\", \"variant_type\", \"mu\"],\n)\n\n# Mutation rates are only available for 32 codons. We need to reverse-complement for the remainder.\ncomplement = {\"A\": \"T\", \"C\": \"G\", \"G\": \"C\", \"T\": \"A\"}\n# Replace ref and alt alleles\n_mu = mu.copy().replace(complement)\n# Reverse-complement trinucleotide contexts\n_mu[\"tri\"] = pd.Series([\"\".join([complement[y] for y in x])[::-1] for x in mu.tri])\nmu = pd.concat([mu, _mu])", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Merge datasets, except for the mutability data\ndf = vep.merge(tri, how=\"left\")\ndf = df.merge(obs, how=\"left\").fillna(0)\ndf = df.merge(cov, how=\"left\")", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Merge methylation and mutability annotations\n\n## Find the number of CpG sites not represented in the ENCODE data\nvariant_types = mu[[\"tri\", \"ref\", \"alt\", \"variant_type\"]].drop_duplicates()\ndf = df.merge(variant_types, how=\"left\")\ndf = df.merge(meth, how=\"left\")\n\n## Print the result\n_ = df[df.variant_type == \"CpG\"][\"lvl\"].isna().value_counts(normalize=True)\nprint(\n    f\"{np.round(_[True]*100, 2)}% of CpG sites are not represented in the methylation data\"\n)\n\n## Assign \"missing\" CpG sites to the mean methylation level\ndf.loc[(df.variant_type == \"CpG\") & (df.lvl.isna()), \"lvl\"] = 2\n\n## All non-CpG sites have lvl 0\ndf.loc[df[\"variant_type\"] != \"CpG\", \"lvl\"] = 0\n\n## Merge with mutability data\ndf = df.merge(mu, how=\"left\")", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "# Expectation model", "metadata": {}}, {"cell_type": "code", "source": "# Weighted linear model\nstats = pd.read_csv(\"../statistics/mutational_model_stats.tsv\", sep=\"\\t\")\nmodel = smf.wls(\"obs ~ sqrt_mu\", data=stats, weights=stats[\"pos\"]).fit()", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "# Summary statistics", "metadata": {}}, {"cell_type": "code", "source": "# OE statistics\ndfg = (\n    df.groupby([\"csq\", \"enst\"])\n    .agg(\n        n_pos=(\"pos\", \"count\"),\n        n_obs=(\"obs\", \"sum\"),\n        sqrt_mu=(\"mu\", lambda x: np.mean(np.sqrt(x))),\n    )\n    .assign(\n        p_obs=lambda x: x[\"n_obs\"] / x[\"n_pos\"],\n        se_p_obs=lambda x: np.sqrt((x[\"p_obs\"] * (1 - x[\"p_obs\"])) / x[\"n_pos\"]),\n        p_exp=lambda x: model.predict(x[\"sqrt_mu\"]),\n        se_p_exp=lambda x: np.sqrt((x[\"p_exp\"] * (1 - x[\"p_exp\"])) / x[\"n_pos\"]),\n        n_exp=lambda x: np.round(x[\"n_pos\"] * x[\"p_exp\"], 2),\n        oe=lambda x: x[\"n_obs\"] / x[\"n_exp\"],\n        oe_ci_upper=lambda x: (x[\"p_obs\"] + stats.norm.ppf(0.975) * (x[\"se_p_obs\"]))\n        / x[\"p_exp\"],\n        ee_ci_lower=lambda x: (x[\"p_exp\"] - stats.norm.ppf(0.975) * (x[\"se_p_exp\"]))\n        / x[\"p_exp\"],\n        oe_diff=lambda x: x[\"oe\"] - x[\"ee_ci_lower\"],\n    )\n    .reset_index()\n)\n# Z scores and p-values\ndfg[\"z\"] = dfg.apply(\n    lambda x: (\n        proportions_ztest(\n            x[\"n_obs\"],\n            x[\"n_pos\"],\n            x[\"p_exp\"],\n            alternative=\"two-sided\",\n            prop_var=x[\"p_exp\"],\n        )[0]\n    ),\n    axis=1,\n)\ndfg[\"p\"] = dfg.apply(\n    lambda x: proportions_ztest(\n        x[\"n_obs\"],\n        x[\"n_pos\"],\n        x[\"p_exp\"],\n        alternative=\"two-sided\",\n        prop_var=x[\"p_exp\"],\n    )[1],\n    axis=1,\n)", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "# Plots", "metadata": {}}, {"cell_type": "markdown", "source": "## Expected and observed variants per transcript", "metadata": {}}, {"cell_type": "code", "source": "# Plot number observed vs number expected per transcript\n# Exclude TTN for visual clarity\nsns.set_context(\"talk\")\ng = sns.lmplot(\n    data=dfg[dfg.enst != \"ENST00000589042\"],\n    x=\"n_exp\",\n    y=\"n_obs\",\n    col=\"csq\",\n    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n    facet_kws={\"sharex\": False, \"sharey\": False},\n    ci=None,\n    height=4,\n)\ng.set_titles(col_template=\"{col_name}\")\ng.set_axis_labels(\"Expected\", \"Observed\")\nfor ax in g.axes[0]:\n    ax.axline((0, 0), (1, 1), color=\"grey\")\ng.fig.subplots_adjust(top=0.8)\ng.fig.suptitle(\"Variants per transcript\");", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## O/E distributions", "metadata": {}}, {"cell_type": "code", "source": "# Plot distributions of O/E ratio per transcript\ng = sns.displot(\n    data=dfg,\n    kind=\"kde\",\n    x=\"oe\",\n    col=\"csq\",\n    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n    facet_kws={\"sharex\": False, \"sharey\": False},\n    height=4,\n)\ng.set_titles(col_template=\"{col_name}\")\ng.set_axis_labels(\"O/E\")\ng.set(xlim=(0, 2))\ng.fig.subplots_adjust(top=0.8)\ng.fig.suptitle(\"O/E ratio per transcript\");", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## O/E upper confidence interval distribution", "metadata": {}}, {"cell_type": "code", "source": "# Plot distributions of O/E upper confidence interval per transcript\ng = sns.displot(\n    data=dfg,\n    kind=\"kde\",\n    x=\"oe_ci_upper\",\n    col=\"csq\",\n    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n    facet_kws={\"sharex\": False, \"sharey\": False},\n    height=4,\n)\ng.set_titles(col_template=\"{col_name}\")\ng.set_axis_labels(\"O/E upper 95% CI\")\ng.set(xlim=(0, 2))\ng.fig.subplots_adjust(top=0.8)\ng.fig.suptitle(\"O/E upper 95% confidence interval per transcript\");", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## O/E difference from E/E lower confidence interval", "metadata": {}}, {"cell_type": "code", "source": "# Plot distributions of O/E difference from E/E lower 95% confidence interval per transcript\ng = sns.displot(\n    data=dfg,\n    kind=\"kde\",\n    x=\"oe_diff\",\n    col=\"csq\",\n    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n    facet_kws={\"sharex\": True, \"sharey\": False},\n    height=4,\n)\ng.set_titles(col_template=\"{col_name}\")\ng.set_axis_labels(\"O/E difference\")\ng.set(xlim=(-1, 1))\ng.fig.subplots_adjust(top=0.8)\ng.fig.suptitle(\"O/E difference from E/E lower 95% confidence interval per transcript\");", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## N expected by consequence", "metadata": {}}, {"cell_type": "code", "source": "# Plot distributions of n_exp per transcript\nsns.set_context(\"talk\")\ng = sns.displot(\n    data=dfg,\n    kind=\"ecdf\",\n    x=\"n_exp\",\n    col=\"csq\",\n    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n    facet_kws={\"sharex\": False, \"sharey\": False},\n    height=4,\n)\ng.set_titles(col_template=\"{col_name}\")\ng.set_axis_labels(\"Expected\")\n\n# Set x-axis limits\ng.axes[0, 0].set_xlim(0, 200)\ng.axes[0, 1].set_xlim(0, 500)\ng.axes[0, 2].set_xlim(0, 20)\ng.fig.subplots_adjust(top=0.8)\ng.fig.suptitle(\"Expected variants per transcript\");", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## One-sample Z score", "metadata": {}}, {"cell_type": "code", "source": "# Plot distributions of one-sample Z scores per transcript\nsns.set_context(\"talk\")\ng = sns.displot(\n    data=dfg,\n    kind=\"kde\",\n    x=\"z\",\n    col=\"csq\",\n    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n    facet_kws={\"sharex\": True, \"sharey\": False},\n    height=4,\n)\ng.set_titles(col_template=\"{col_name}\")\ng.set_axis_labels(\"Z\")\ng.set(xlim=(-10, 5))\ng.fig.subplots_adjust(top=0.8)\ng.fig.suptitle(\"One-sample Z-scores per transcript\");", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## P-values", "metadata": {}}, {"cell_type": "code", "source": "# Plot distributions of p-values per transcript\nsns.set_context(\"talk\")\ng = sns.displot(\n    data=dfg,\n    kind=\"kde\",\n    x=\"p\",\n    col=\"csq\",\n    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n    facet_kws={\"sharex\": True, \"sharey\": False},\n    height=4,\n)\ng.set_titles(col_template=\"{col_name}\")\ng.set_axis_labels(\"p\")\ng.set(xscale=\"log\")\ng.set(xlim=(0, 1))\ng.fig.subplots_adjust(top=0.8)\ng.fig.suptitle(\"p-values per transcript\");", "metadata": {}, "execution_count": null, "outputs": []}]}
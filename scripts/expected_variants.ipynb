{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551c7ab8",
   "metadata": {},
   "source": [
    "# Expected variants\n",
    "This script determines the expected number of variants per transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a51852a",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611b046",
   "metadata": {},
   "source": [
    "### Install libraries to worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a2f36f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 23.1.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.3\n",
      "  latest version: 23.1.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda install statsmodels -y\n",
    "! conda install scikit-learn -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b9b15",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86cece78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats as _stats\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656b2a0e",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e4b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VCF headers and datatypes.\n",
    "_header = [\"chr\", \"pos\", \"id\", \"ref\", \"alt\", \"qual\", \"filter\", \"info\"]\n",
    "\n",
    "datatypes = defaultdict(lambda: \"str\")\n",
    "datatypes.update({\"pos\": np.int32, \"ac\": np.int32, \"an\": np.int32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e85652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreive observed variants\n",
    "obs = pd.read_csv(\n",
    "    \"../data/all_pass_snvs.txt\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=_header + [\"ac\", \"an\"],\n",
    "    usecols=[\"chr\", \"pos\", \"ref\", \"alt\", \"ac\", \"an\"],\n",
    "    dtype=datatypes,\n",
    ").assign(obs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20422f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreive VEP annotations of all possible SNVs\n",
    "vep = pd.read_csv(\n",
    "    \"../data/vep_cds_all_possible_snvs.vcf\",\n",
    "    sep=\"\\t\",\n",
    "    comment=\"#\",\n",
    "    header=None,\n",
    "    names=_header,\n",
    "    dtype=datatypes,\n",
    "    usecols=[\"chr\", \"pos\", \"ref\", \"alt\", \"info\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bdb67c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get enst\n",
    "vep[\"enst\"] = pd.Series([x.split(\"|\", 3)[2] for x in vep[\"info\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a40909c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get csq\n",
    "syn = pd.Series([\"synonymous\" in x for x in vep[\"info\"]])\n",
    "mis = pd.Series([\"missense\" in x for x in vep[\"info\"]])\n",
    "non = pd.Series([\"stop_gained\" in x for x in vep[\"info\"]])\n",
    "\n",
    "vep.loc[syn, \"csq\"] = \"synonymous\"\n",
    "vep.loc[mis, \"csq\"] = \"missense\"\n",
    "vep.loc[non, \"csq\"] = \"nonsense\"\n",
    "\n",
    "vep = vep.drop(\"info\", axis=1).dropna()  # Keep only syn/mis/non variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c425be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trinucleotide contexts\n",
    "tri = pd.read_csv(\n",
    "    \"../data/cds_trinucleotide_contexts.tsv\", sep=\"\\t\", dtype=datatypes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07c9e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnomAD methylation data\n",
    "meth = (pd.read_csv(\"../data/grch38_cpg_methylation.tsv\", \n",
    "                    sep=\"\\t\",\n",
    "                    header=0,\n",
    "                    names=[\"ix\",\"chr\",\"pos\",\"alleles\",\"lvl\"],\n",
    "                    usecols=[\"chr\",\"pos\",\"lvl\"],\n",
    "                   )\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3108156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutation rates\n",
    "mu = pd.read_csv(\n",
    "    \"../data/gnomad_nc_mutation_rates.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"tri\", \"ref\", \"alt\", \"lvl\", \"variant_type\", \"mu\", \"pos\", \"obs\", \"po\", \"ppo\",],\n",
    "    header=0,\n",
    "    usecols=[\"tri\", \"ref\", \"alt\", \"lvl\", \"mu\", \"variant_type\"],\n",
    ")\n",
    "\n",
    "# Mutation rates are only available for 32 codons. We need to reverse-complement for the remainder.\n",
    "complement = {\"A\": \"T\", \"C\": \"G\", \"G\": \"C\", \"T\": \"A\"}\n",
    "# Replace ref and alt alleles\n",
    "_mu = mu.copy().replace(complement)\n",
    "# Reverse-complement trinucleotide contexts\n",
    "_mu[\"tri\"] = pd.Series([\"\".join([complement[y] for y in x])[::-1] for x in mu.tri])\n",
    "mu = pd.concat([mu, _mu])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d977b",
   "metadata": {},
   "source": [
    "## Merge annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fc588d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge VEP, context, and observed variant annotations\n",
    "df = vep.merge(tri, how=\"left\")\n",
    "df = df.merge(obs, how=\"left\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb03a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge methylation annotations\n",
    "variant_types = mu[[\"tri\", \"ref\", \"alt\", \"variant_type\"]].drop_duplicates()\n",
    "df = df.merge(variant_types, how=\"left\")\n",
    "df = df.merge(meth, how=\"left\")\n",
    "\n",
    "# All non-CpG sites have lvl 0\n",
    "df.loc[df[\"variant_type\"] != \"CpG\", \"lvl\"] = 0\n",
    "df.lvl = df.lvl.astype(int)\n",
    "\n",
    "# Merge with mutability data\n",
    "df = df.merge(mu, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a76f8c",
   "metadata": {},
   "source": [
    "## Expectation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac5534b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summary statistics\n",
    "stats = pd.read_csv(\"../outputs/mutational_model_stats.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Exclude saturated contexts\n",
    "stats_nonsat = stats[stats[\"obs\"] != 1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf11a0a",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "653ec2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to retrieve the standard error of a proportion\n",
    "def sem(p, n): return np.sqrt((p*(1-p))/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2d3b0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.9939 for \"obs\" vs \"fit_obs\"\n"
     ]
    }
   ],
   "source": [
    "# Get an exponential regression equation \n",
    "# Weighted by 1 / sem(\"obs\"), as per gnomAD paper\n",
    "fit = np.polyfit(stats_nonsat[\"mu\"], np.log(1 - stats_nonsat[\"obs\"]), 1, w=(1/sem(stats_nonsat[\"obs\"], stats_nonsat[\"pos\"])))\n",
    "\n",
    "# Create a polynomial evaluator\n",
    "p = np.poly1d(fit)\n",
    "\n",
    "# Fit the model to estimate the observed proportion\n",
    "stats_nonsat[\"fit_obs\"] = 1 - np.exp(p(stats_nonsat[\"mu\"]))\n",
    "\n",
    "# R2 for \"obs\" vs \"fit_obs\"\n",
    "print(f'R2 = {np.round(r2_score(stats_nonsat[\"obs\"], stats_nonsat[\"fit_obs\"]), 5)} for \"obs\" vs \"fit_obs\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1e62d",
   "metadata": {},
   "source": [
    "# Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8335d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OE statistics\n",
    "dfg = (\n",
    "    df.groupby([\"enst\", \"csq\"])\n",
    "    .agg(\n",
    "        n_pos=(\"pos\", \"count\"),\n",
    "        n_obs=(\"obs\", \"sum\"),\n",
    "        mu=(\"mu\", \"mean\"),\n",
    "    )\n",
    "    .assign(\n",
    "        prop_obs=lambda x: x[\"n_obs\"] / x[\"n_pos\"],\n",
    "        se_prop_obs=lambda x: np.sqrt((x[\"prop_obs\"] * (1 - x[\"prop_obs\"])) / x[\"n_pos\"]),\n",
    "        prop_exp=lambda x: 1 - np.exp(p(x[\"mu\"])),\n",
    "        se_prop_exp=lambda x: np.sqrt((x[\"prop_exp\"] * (1 - x[\"prop_exp\"])) / x[\"n_pos\"]),\n",
    "        n_exp=lambda x: np.round(x[\"n_pos\"] * x[\"prop_exp\"], 2),\n",
    "        oe=lambda x: x[\"n_obs\"] / x[\"n_exp\"],\n",
    "        oe_ci_upper=lambda x: (x[\"prop_obs\"] + _stats.norm.ppf(0.975) * (x[\"se_prop_obs\"])) / x[\"prop_exp\"],\n",
    "        ee_ci_lower=lambda x: (x[\"prop_exp\"] - _stats.norm.ppf(0.975) * (x[\"se_prop_exp\"])) / x[\"prop_exp\"],\n",
    "        oe_diff=lambda x: (x[\"oe\"] - x[\"ee_ci_lower\"]),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "# Z scores and p-values\n",
    "dfg[\"z\"] = dfg.apply(\n",
    "    lambda x: (\n",
    "        proportions_ztest(\n",
    "            x[\"n_obs\"],\n",
    "            x[\"n_pos\"],\n",
    "            x[\"prop_exp\"],\n",
    "            alternative=\"smaller\",\n",
    "            prop_var=x[\"prop_exp\"],\n",
    "        )[0]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "dfg[\"p\"] = dfg.apply(\n",
    "    lambda x: proportions_ztest(\n",
    "        x[\"n_obs\"],\n",
    "        x[\"n_pos\"],\n",
    "        x[\"prop_exp\"],\n",
    "        alternative=\"smaller\",\n",
    "        prop_var=x[\"prop_exp\"],\n",
    "    )[1],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "346d25a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.to_csv(\"../outputs/expected_variants_stats.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e673e",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40419286",
   "metadata": {},
   "source": [
    "### Expected and observed variants per transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number observed vs number expected per transcript\n",
    "# Exclude TTN for visual clarity\n",
    "sns.set_context(\"talk\")\n",
    "g = sns.lmplot(\n",
    "    data=dfg[dfg.enst != \"ENST00000589042\"],\n",
    "    x=\"n_exp\",\n",
    "    y=\"n_obs\",\n",
    "    col=\"csq\",\n",
    "    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n",
    "    facet_kws={\"sharex\": False, \"sharey\": False},\n",
    "    ci=None,\n",
    "    #height=4,\n",
    ")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.set_axis_labels(\"Expected\", \"Observed\")\n",
    "for ax in g.axes[0]:\n",
    "    ax.axline((0, 0), (1, 1), color=\"grey\")\n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(\"Variants per transcript\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12b8a4f",
   "metadata": {},
   "source": [
    "## O/E distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of O/E ratio per transcript\n",
    "g = sns.displot(\n",
    "    data=dfg,\n",
    "    kind=\"kde\",\n",
    "    x=\"oe\",\n",
    "    col=\"csq\",\n",
    "    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n",
    "    facet_kws={\"sharex\": False, \"sharey\": False},\n",
    "    height=4,\n",
    ")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.set_axis_labels(\"O/E\")\n",
    "g.set(xlim=(0, 2))\n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(\"O/E ratio per transcript\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569bdbe",
   "metadata": {},
   "source": [
    "## O/E upper confidence interval distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of O/E upper confidence interval per transcript\n",
    "g = sns.displot(\n",
    "    data=dfg,\n",
    "    kind=\"kde\",\n",
    "    x=\"oe_ci_upper\",\n",
    "    col=\"csq\",\n",
    "    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n",
    "    facet_kws={\"sharex\": False, \"sharey\": False},\n",
    "    height=4,\n",
    ")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.set_axis_labels(\"O/E upper 95% CI\")\n",
    "g.set(xlim=(0, 2))\n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(\"O/E upper 95% confidence interval per transcript\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed60d00",
   "metadata": {},
   "source": [
    "## O/E difference from E/E lower confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of O/E difference from E/E lower 95% confidence interval per transcript\n",
    "g = sns.displot(\n",
    "    data=dfg,\n",
    "    kind=\"kde\",\n",
    "    x=\"oe_diff\",\n",
    "    col=\"csq\",\n",
    "    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n",
    "    facet_kws={\"sharex\": True, \"sharey\": False},\n",
    "    height=4,\n",
    ")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.set_axis_labels(\"O/E difference\")\n",
    "g.set(xlim=(-1, 1))\n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(\"O/E difference from E/E lower 95% confidence interval per transcript\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974168b",
   "metadata": {},
   "source": [
    "## N expected by consequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf00022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of n_exp per transcript\n",
    "sns.set_context(\"talk\")\n",
    "g = sns.displot(\n",
    "    data=dfg,\n",
    "    kind=\"ecdf\",\n",
    "    x=\"n_exp\",\n",
    "    col=\"csq\",\n",
    "    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n",
    "    facet_kws={\"sharex\": False, \"sharey\": False},\n",
    "    height=4,\n",
    ")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.set_axis_labels(\"Expected\")\n",
    "\n",
    "# Set x-axis limits\n",
    "g.axes[0, 0].set_xlim(0, 200)\n",
    "g.axes[0, 1].set_xlim(0, 500)\n",
    "g.axes[0, 2].set_xlim(0, 20)\n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(\"Expected variants per transcript\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c383cf3",
   "metadata": {},
   "source": [
    "## One-sample Z score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1603f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of one-sample Z scores per transcript\n",
    "sns.set_context(\"talk\")\n",
    "g = sns.displot(\n",
    "    data=dfg,\n",
    "    kind=\"kde\",\n",
    "    x=\"z\",\n",
    "    col=\"csq\",\n",
    "    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n",
    "    facet_kws={\"sharex\": True, \"sharey\": False},\n",
    "    height=4,\n",
    ")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.set_axis_labels(\"Z\")\n",
    "g.set(xlim=(-10, 5))\n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(\"One-sample Z-scores per transcript\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d337845",
   "metadata": {},
   "source": [
    "## P-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c37599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of p-values per transcript\n",
    "sns.set_context(\"talk\")\n",
    "g = sns.displot(\n",
    "    data=dfg,\n",
    "    kind=\"kde\",\n",
    "    x=\"p\",\n",
    "    col=\"csq\",\n",
    "    col_order=[\"synonymous\", \"missense\", \"nonsense\"],\n",
    "    facet_kws={\"sharex\": True, \"sharey\": False},\n",
    "    height=4,\n",
    ")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.set_axis_labels(\"p\")\n",
    "g.set(xscale=\"log\")\n",
    "g.set(xlim=(0, 1))\n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(\"p-values per transcript\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
